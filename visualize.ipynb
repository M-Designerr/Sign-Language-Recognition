{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Import libraries\n",
    "\n",
    "# Step 2: Load the images\n",
    "data_dir = 'data_digit/train'\n",
    "images = []\n",
    "labels = []\n",
    "for foldername in os.listdir(data_dir):\n",
    "    folderpath = os.path.join(data_dir, foldername)\n",
    "    for filename in os.listdir(folderpath):\n",
    "        img = Image.open(os.path.join(folderpath, filename))\n",
    "        images.append(np.array(img))\n",
    "        labels.append(foldername)\n",
    "\n",
    "# Step 3: Preprocess the data\n",
    "X_resized = []\n",
    "for i in range(len(images)):\n",
    "    im = Image.fromarray(images[i])\n",
    "    im_resized = im.resize((128, 128))\n",
    "    X_resized.append(np.array(im_resized))\n",
    "X_resized = np.array(X_resized)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "X_norm = X_resized / 255.0\n",
    "\n",
    "# Create image augmentations to increase the size of the dataset\n",
    "# X_augmented = []\n",
    "# for i in range(len(images)):\n",
    "#     im = Image.fromarray(images[i])\n",
    "#     im_flip = im.transpose(method=Image.FLIP_LEFT_RIGHT)\n",
    "#     im_rot = im.rotate(10)\n",
    "#     im_bright = im.point(lambda x: x * 1.2)\n",
    "#     X_augmented.extend([np.array(im), np.array(im_flip), np.array(im_rot), np.array(im_bright)])\n",
    "# X_augmented = np.array(X_augmented)\n",
    "\n",
    "# Step 4: Create labels\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Step 5: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Save the dataset\n",
    "dataset = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
    "with open('dataset.pickle', 'wb') as handle:\n",
    "    pickle.dump(dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"model/\"\n",
    "json_file_num = open(directory+\"model-bw-digit.json\", \"r\")\n",
    "model_json_num = json_file_num.read()\n",
    "json_file_num.close()\n",
    "loaded_model_num = model_from_json(model_json_num)\n",
    "loaded_model_num.load_weights(directory+\"model-bw-digit.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 67ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model_num.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2979, 128, 128)\n",
      "(745, 128, 128)\n",
      "(2979,)\n",
      "(745,)\n",
      "(745, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [np.argmax(labels) for labels in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.astype(str)\n",
    "y_pred = np.array(y_pred).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '_0'],\n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 69,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 60,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 63,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 72,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 67,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 60,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 75,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 58,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 77,  0],\n",
       "       [ 0,  0, 59,  0,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (12, 12), indices imply (11, 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     table \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(confusion_matrix(y_test, y_pred), columns\u001b[39m=\u001b[39mcolumn, index\u001b[39m=\u001b[39mindex)\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m table\n\u001b[1;32m----> 8\u001b[0m plot(y_test,y_pred)\n",
      "Cell \u001b[1;32mIn[115], line 5\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(y_test, y_pred)\u001b[0m\n\u001b[0;32m      3\u001b[0m column \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPredicted \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m class_labels]\n\u001b[0;32m      4\u001b[0m index \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mActual \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m class_labels]\n\u001b[1;32m----> 5\u001b[0m table \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(confusion_matrix(y_test, y_pred), columns\u001b[39m=\u001b[39;49mcolumn, index\u001b[39m=\u001b[39;49mindex)\n\u001b[0;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m table\n",
      "File \u001b[1;32mc:\\Users\\mk020\\Desktop\\Sign Language Recognition\\env\\lib\\site-packages\\pandas\\core\\frame.py:722\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    712\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    713\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    714\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    720\u001b[0m         )\n\u001b[0;32m    721\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 722\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    723\u001b[0m             data,\n\u001b[0;32m    724\u001b[0m             index,\n\u001b[0;32m    725\u001b[0m             columns,\n\u001b[0;32m    726\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    727\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    728\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    729\u001b[0m         )\n\u001b[0;32m    731\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\Users\\mk020\\Desktop\\Sign Language Recognition\\env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    345\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[0;32m    346\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[0;32m    347\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\mk020\\Desktop\\Sign Language Recognition\\env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (12, 12), indices imply (11, 11)"
     ]
    }
   ],
   "source": [
    "def plot(y_test,y_pred):\n",
    "    class_labels = unique_labels(y_test)\n",
    "    column = [f'Predicted {label}' for label in class_labels]\n",
    "    index = [f'Actual {label}' for label in class_labels]\n",
    "    table = pd.DataFrame(confusion_matrix(y_test, y_pred), columns=column, index=index)\n",
    "    return table\n",
    "\n",
    "plot(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
